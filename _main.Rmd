---
#####################
## thesis metadata ##
#####################
title: |
  Determining the Influence of Different Variables on the Price of Ikea Products \
  – a Regression Analysis
author: Philip Krück, Johannes Pein
degree: B.Sc. Business Informatics (A Track)
degreedate: 04.12.2020
lecturer: "Lecturer: Ulf Köther"
groupnumber: "Group Number: 7"
modulename: "Digital Toolbox: Data Business"
matriculationnumbers: "Matriculation Numbers: 3938 (P.Krück), **** (J.Pein)"
abbreviations: "front-and-back-matter/abbreviations" # path to .tex file with abbreviations

#######################
## bibliography path ##
#######################
bibliography: references.bib
bibliography-heading-in-pdf: Works Cited

#####################
## PDF formatting  ##
#####################
abstractseparate: false  # include front page w/ abstract for examination schools?
bib-humanities: true   #set to true if you want in-text references formatted as author-year
doi-in-bibliography: true #set to true if you want DOI's to be shown in the bibliography
draft: false # add as DRAFT mark in the footer?
page-layout: nobind #'nobind' for PDF output (equal margins), 'twoside' for two-sided binding (mirror margins and blank pages), leave blank for one-sided binding (left margin > right margin)
hidelinks: true #if false, the PDF output highlights clickable links with a colored border - you will probably want to set this to true for PDF version you wish to physically print
toc-depth: 2 # depth of heading to include in table of contents
lof: true # list of figures in front matter?
lot: true # list of tables in front matter?
mini-toc: fase  # mini-table of contents at start of each chapter? (this just prepares it; you must also add \minitoc after the chapter titles)
mini-lot: false  # mini-list of tables by start of each chapter?
mini-lof: false  # mini-list of figures by start of each chapter?

params:
  corrections: true # set false to stop applying blue background to blocks of corrections

#####################
## output options  ##
#####################
output:
  bookdown::pdf_book:
    template: templates/template.tex
    keep_tex: true
    citation_package: biblatex  
    pandoc_args: ["--lua-filter=scripts_and_filters/correction_filter.lua"] #remove filter to stop applying blue background to inline corrections
  bookdown::gitbook:
    css: templates/style.css
    config:
      sharing:
        facebook: false
        twitter: yes
        all: false
  bookdown::word_document2:
    toc: true   
link-citations: true
documentclass: book

---


```{r create_chunk_options, include=FALSE, eval=knitr::is_latex_output()}
source('scripts_and_filters/create_chunk_options.R')
source('scripts_and_filters/wrap_lines.R')
```

``` {r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(readr)
ikea <- read_delim("ikea.csv", ";", 
                   escape_double = FALSE, 
                   trim_ws = TRUE,
                   col_types = cols(
                     name = col_factor(),
                     category = col_factor(),
                     designer = col_factor()
                   )
                  )

# tidy data

## tidy designer
tidy_ikea <- ikea

tidy_ikea$designer[grepl("\\d",tidy_ikea$designer)] <- NA


tidy_ikea <- tidy_ikea %>%
  separate(designer, c("d1", "d2", "d3", "d4", "d5", "d6", "d7"), sep = "/")

tidy_ikea[ , 11:17][tidy_ikea[ , 11:17] == "IKEA of Sweden" ] <- NA
tidy_ikea[ , 11:17] <- t(apply(tidy_ikea[ , 11:17], 1, function(x) c(sort(x[x!='']), x[x==''])))

tidy_ikea <- tidy_ikea %>%
  unite(col = "designer", d1, d2, d3, d4, d5, d6, d7, sep = ", ", na.rm = TRUE)

tidy_ikea$designer[tidy_ikea$designer == ""] <- NA

## convert other colors to boolean
tidy_ikea <- tidy_ikea %>%
  mutate(other_colors = other_colors == "Yes")

## convert old price to integer and times 10
tidy_ikea <- tidy_ikea %>%
  mutate(old_price = str_replace(old_price, "SR ", "")) %>%
  mutate(old_price = str_replace_all(old_price, ",", "")) %>%
  mutate(old_price = strtoi(old_price)) %>%
  mutate(old_price = old_price * 10)
  
# transform data columns

# add size in m^3
tidy_ikea <- tidy_ikea %>%
  mutate(size_m3 = round(depth/100 * width/100 * height/100, 2))

# transform price and old price in eur
sr_to_eur_conversion_factor <- 0.24537 # conversion factor from 20.04.2020 (https://www.xe.com/de/currencyconverter/convert/?Amount=1&From=EUR&To=SAR)

tidy_ikea <- tidy_ikea %>%
  mutate(price_eur = round(price * sr_to_eur_conversion_factor / 10, 2), old_price_eur = round(old_price * sr_to_eur_conversion_factor / 10, 2))

## select relevant data
tidy_ikea <- tidy_ikea %>%
  select(name, category, price_eur, old_price_eur, sellable_online, other_colors, designer, size_m3)
```

``` {r echo=FALSE, message=FALSE}
# setup color theme
library('RColorBrewer')
num_cols <- 17
mycolors <- colorRampPalette(brewer.pal(12, "Set3"))(num_cols) # add a custom color palette
```

<!--chapter:end:index.Rmd-->

---
#########################################
# options for knitting a single chapter #
#########################################
output:
  bookdown::html_document2: default
  bookdown::word_document2: default
  bookdown::pdf_document2:
    template: templates/brief_template.tex
documentclass: book
bibliography: references.bib
---

# Introduction {#intro}
``` {r echo=FALSE, fig.cap="Sample plot", out.width="100%", message=FALSE}
ggplot(data = tidy_ikea) +
  geom_bar(mapping = aes(x = other_colors, fill = other_colors), show.legend = FALSE) +
  scale_fill_manual(values = mycolors) +
  theme_minimal() +
  labs(x = "other colors", y = "# of items", title = "Number of Items with Other Colors") 
```

<!--chapter:end:01-introduction.Rmd-->

---
#########################################
# options for knitting a single chapter #
#########################################
output:
  bookdown::html_document2: default
  bookdown::word_document2: default
  bookdown::pdf_document2:
    template: templates/brief_template.tex
documentclass: book
bibliography: references.bib
---

# Theoretical Background & Research Question 

## Background on the Data Set
The data set was obtained by a kaggle.com user (Reem Abdulrahman) by the means of webscraping techniques from the Saudi Arabian Ikea website in the furniture category on the 20th of April 2020. Noteworthy features include the name, category, price in Saudi Riyals, the designer and dimensions (width, height and depth). The data set has 13 variables and 2962 observations.


## Theoretical Background {#theoretical_background}

### Overfitting
->Johannes

### Random Forest
->Johannes
- basics

### Feature Importance
->Johannes

## Research Question {#research_question}
This paper explores the influence for different variables on the price in the given data set. The motivating forces for this research question are the possible implications for price determination of new items.

<!--chapter:end:02-background-research-question.Rmd-->

---
output:
  #bookdown::html_document2: default
  #bookdown::word_document2: default
  bookdown::pdf_document2:
    template: templates/brief_template.tex
documentclass: book
bibliography: references.bib
---

# Methods {#methods}


## Data Cleaning and Transformatoin {#datacleaning}
To examine the given data set properly, the authors first had to restructure and reformat it. This initial data cleaning step included type conversion, value mutation, addition of newly calculated fields and the removal of irrelevant columns.
Concretely, name, category and designer were converted to categorical variables. In the designer column, blank strings and values prefixed by “IKEA of Sweden” were converted to missing values (```NA```). Furthermore, both the price and old price were converted to double values and the currency was changed from Saudi Arabian Riyals to Euros based on the exchange rate from the time the data set was obtained by the author \@ref(#theoretical_background).

Interestingly, the data set had a peculiarity where some rows were exact duplicates except for the category value. The authors considered multiple approaches to handle these data duplications without losing information about the category of an item. 

One considered option was to merge the two category values into one column value via comma separation (e.g. ```"a"``` and ```"b"``` converts to ```"a, b"```). However, this approach leads to the creation of many combinatorial categories with a low count of items per category which also reduces the item count per category where the category isn't comma separated. Overall this would lead to having many small categories which increases the difficulty in applying a regression model due to overfitting \@ref(#overfitting).

The second option was to create separate columns for the different values of ```category```. The data set would then have observations with category one, two and three. While no information is lost utilizing this approach, most observations in the second and third category column would contain missing values, thus increasing the difficulty of analysis using a predefined model @\ref(#random_forest_model).

The authors chose the option of selecting the observations out of the duplicates where the category count occurred most frequently when considering duplicates. The most important categories could be retained without including more column vectors into the data set as in option two.

To better facilitate the comparison of the different sizes of furniture items, the size in cubic meters was computed based on the depth, width and height values, and added as a column vector for further analysis. 
Finally, the authors only selected columns that could have a potential impact on the analysis \@ref(#research_question) for further investigation. A detailed comparison of the initial vs. transformed data structure can be seen in tables \@ref(tab:initial-ikea) and \@ref(tab:tidy-ikea).




TODO: Format these tables
```{r initial-ikea, echo=FALSE}
library('kableExtra')

knitr::kable(head(ikea), caption = "Initial Data Set formatting.")
```

```{r tidy-ikea, echo=FALSE}
knitr::kable(head(tidy_ikea), caption = "Data Set after cleaning process.")
```



## Exploratory Data Analysis {#tbd}
The following sections explore our data based on the eight step data exploration protocol proposed by Zuur et al [@Zuur2010]. 


### Step 1: Outliers in Price and Independent Variables
Outliers of the chosen variables (from tidying see \@ref(#datacleaning) can be observed for each variable (see plot ...). 
The authors assume that outliers do not occur randomly in the form of an observer error. Web scraping code is written in a generic form which makes it generalizable to all applied pages. Thus takes human observation errors out of the equation. Additionally, the authors looked at individual outlier (stichprobenartig) examples and used the provided link column to manually double check observations against machine errors.
By the stated assumption, all outliers are meaningful for further analysis.



### Step 2: Homogeneity of Price
The homogeneity (homoscedasticity) of variance for price is explored by the means of conditional boxplotting. 
Within each name, and within each category the variance is heterogenous (see fig. \@ref(fig:homogeneity)). However, looking at both name and category in conjunction, it is possible to explore homoscedasticity of variance for price.

In the context of this paper, the authors weren't able to inspect all variable combinations for the five categorical variables ($2^3=8$).


```{r, homogeneity, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, fig.cap="Homogeneity of category for selected combinations of name and category", out.width="100%"}
tidy_ikea %>%
  filter(name == "HEMNES" | name == "LIDHULT" | name == "VIMLE" | name == "VALLENTUNA" | name == "GRÖNLID") %>%
  filter(category == "Beds" | category == "Chairs" | category == "Sofas & armchairs") %>%
  ggplot(mapping = aes(x = reorder(name, price_eur), y = price_eur, color = name)) +
  geom_boxplot(width = 0.4, outlier.size = 0.5, outlier.alpha = 0.3, show.legend = FALSE) + 
  scale_color_manual(values = mycolors) +
  theme_minimal() +
  coord_flip() +
  labs(x = "name", y = "price in Euro", fill = "", subtitle = "category") +
  facet_grid(~ category)
```



### Step 3: Missing Value Trouble
All numerical variables (```price```, ```old_price``` and ```size_m3```) aren't arranged along a normal distribution (see fig. \@ref(fig:normality)), but rather follow an exponential decay ($e^{-x}$).


```{r, normality, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, fig.cap="Homogeneity of category for selected combinations of name and category", out.width="100%"}
tidy_ikea %>%
  select(where(is.numeric)) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "num") %>% group_by(variable) %>%
  arrange(num) %>%
  mutate(observation = 1:n()) %>%
  ungroup() %>%
  ggplot(aes(x = num)) + theme_bw() +
  geom_histogram(bins = 100) + facet_wrap(~ variable, scales = "free") + ylab("") + xlab("")
```



### Step 4: Missing Values
All variables were examined for missing values. Only ```designer```, ```size_m3``` and ```old_price_eur```have missing values of 3.44%, 45.9% and 81% respectively (see fig. \@ref(fig:missing-values))). 
The missing values for designer were deliberately set to ```NA``` by the authors in the case where the values contained digits, which is clearly a scraping error. 
The ```NA``` values for the size can be explained due to the computation of this column vector. ```size_m3``` is the product of ```depth```, ```width``` and ```height```. If one of those three values is missing, the end result is also a missing value. 
The abscence of the old price variables is due to the fact that most items aren't on sale and thus don't have a missing value.

```{r, missing-values, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, fig.cap="Homogeneity of category for selected combinations of name and category", out.width="100%"}
missing_values <- tidy_ikea %>%
  gather(key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  group_by(key) %>%
  mutate(total = n()) %>%
  group_by(key, total, isna) %>%
  summarise(num.isna = n()) %>%
  mutate(pct = num.isna / total * 100)
## `summarise()` regrouping output by 'key', 'total' (override with `.groups` argument)
levels <-
  (missing_values  %>% filter(isna == T) %>% arrange(desc(pct)))$key

missing_values %>%
  ggplot() +
  geom_bar(aes(x = reorder(key, desc(pct)), 
               y = pct, fill=isna), 
           stat = 'identity', alpha=0.8) +
  scale_x_discrete(limits = levels) +
  scale_fill_manual(name = "", 
                    values = c('steelblue', 'tomato3'), labels = c("Present", "Missing")) +
  coord_flip() +
  labs(title = "Percentage of missing values", x =
         'Variable', y = "% of missing values")
```


### Step 5: Collinearity between Independent Variables
The correlation between the old price and price is extremely high. However, since the old price is abscent in 81% of the items, it isn't a reliable predictor for the independent variable (price). A relatively high correlation of 82.67% can be observed between price and size. 
However, the multicollinearity of price is rather low whereas the multicollinearity of price is very high which can be observed from the respecteive variance inflation factors (see appendix ...).

```
##################################################################
#Below are some functions that we took from the pairs help file and
#modified, or wrote ourselves. You need to copy and paste all these commands
#into R. It is perhaps better not to try and understand what it all does.



## put correlations on the panels,
## with size proportional to the correlations.
panel.cor <- function(x, y, digits=1, prefix="", cex.cor)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r1=cor(x,y,use="pairwise.complete.obs")
    r <- abs(cor(x, y,use="pairwise.complete.obs"))

    txt <- format(c(r1, 0.123456789), digits=digits)[1]
    txt <- paste(prefix, txt, sep="")
    if(missing(cex.cor)) cex <- 0.9/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex * r)
}

panel.smooth2=function (x, y, col = par("col"), bg = NA, pch = par("pch"),
    cex = 1, col.smooth = "red", span = 2/3, iter = 3, ...)
{
    points(x, y, pch = pch, col = col, bg = bg, cex = cex)
    ok <- is.finite(x) & is.finite(y)
    if (any(ok))
        lines(stats::lowess(x[ok], y[ok], f = span, iter = iter),
            col = 1, ...)
}


panel.lines2=function (x, y, col = par("col"), bg = NA, pch = par("pch"),
    cex = 1, ...)
{
    points(x, y, pch = pch, col = col, bg = bg, cex = cex)
    ok <- is.finite(x) & is.finite(y)
    if (any(ok)){
        tmp=lm(y[ok]~x[ok])
        abline(tmp)}

}




panel.hist <- function(x, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col="white", ...)
}



#VIF
myvif <- function(mod) {
  v <- vcov(mod)
  assign <- attributes(model.matrix(mod))$assign
  if (names(coefficients(mod)[1]) == "(Intercept)") {
    v <- v[-1, -1]
    assign <- assign[-1]
  } else warning("No intercept: vifs may not be sensible.")
  terms <- labels(terms(mod))
  n.terms <- length(terms)
  if (n.terms < 2) stop("The model contains fewer than 2 terms")
  if (length(assign) > dim(v)[1] ) {
     diag(tmp_cor)<-0
     if (any(tmp_cor==1.0)){
        return("Sample size is too small, 100% collinearity is present")
     } else {
        return("Sample size is too small")
     }
  }
  R <- cov2cor(v)
  detR <- det(R)
  result <- matrix(0, n.terms, 3)
  rownames(result) <- terms
  colnames(result) <- c("GVIF", "Df", "GVIF^(1/2Df)")
  for (term in 1:n.terms) {
    subs <- which(assign == term)
    result[term, 1] <- det(as.matrix(R[subs, subs])) * det(as.matrix(R[-subs, -subs])) / detR
    result[term, 2] <- length(subs)
  }
  if (all(result[, 2] == 1)) {
    result <- data.frame(GVIF=result[, 1])
  } else {
    result[, 3] <- result[, 1]^(1/(2 * result[, 2]))
  }
  invisible(result)
}

corvif <- function(dataz) {
    dataz <- as.data.frame(dataz)
    #correlation part
    cat("Correlations of the variables\n\n")
    tmp_cor <- cor(dataz,use="complete.obs")
    print(tmp_cor)

    #vif part
    form    <- formula(paste("fooy ~ ",paste(strsplit(names(dataz)," "),collapse=" + ")))
    dataz   <- data.frame(fooy=1,dataz)
    lm_mod  <- lm(form,dataz)

    cat("\n\nVariance inflation factors\n\n")
    print(myvif(lm_mod))
}

myvif <- function(mod) {
  v <- vcov(mod)
  assign <- attributes(model.matrix(mod))$assign
  if (names(coefficients(mod)[1]) == "(Intercept)") {
    v <- v[-1, -1]
    assign <- assign[-1]
  } else warning("No intercept: vifs may not be sensible.")
  terms <- labels(terms(mod))
  n.terms <- length(terms)
  if (n.terms < 2) stop("The model contains fewer than 2 terms")
  if (length(assign) > dim(v)[1] ) {
     diag(tmp_cor)<-0
     if (any(tmp_cor==1.0)){
        return("Sample size is too small, 100% collinearity is present")
     } else {
        return("Sample size is too small")
     }
  }
  R <- cov2cor(v)
  detR <- det(R)
  result <- matrix(0, n.terms, 3)
  rownames(result) <- terms
  colnames(result) <- c("GVIF", "Df", "GVIF^(1/2Df)")
  for (term in 1:n.terms) {
    subs <- which(assign == term)
    result[term, 1] <- det(as.matrix(R[subs, subs])) * det(as.matrix(R[-subs, -subs])) / detR
    result[term, 2] <- length(subs)
  }
  if (all(result[, 2] == 1)) {
    result <- data.frame(GVIF=result[, 1])
  } else {
    result[, 3] <- result[, 1]^(1/(2 * result[, 2]))
  }
  invisible(result)
}



corvif <- function(dataz) {
    dataz <- as.data.frame(dataz)
    #correlation part
    cat("Correlations of the variables\n\n")
    tmp_cor <- cor(dataz,use="complete.obs")
    print(tmp_cor)

    #vif part
    form    <- formula(paste("fooy ~ ",paste(strsplit(names(dataz)," "),collapse=" + ")))
    dataz   <- data.frame(fooy=1,dataz)
    lm_mod  <- lm(form,dataz)

    cat("\n\nVariance inflation factors\n\n")
    print(myvif(lm_mod))
}

```



```{r, collinearity, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, fig.cap="Homogeneity of category for selected combinations of name and category", out.width="100%"}

tidy_ikea %>% select(where(is.numeric)) %>% corvif()
tidy_ikea %>% select(where(is.numeric) & -old_price_eur) %>% corvif()





```





### Step 6: Relationship between Independent Variables and Price
- from eda_covariance.Rc (in Anhang + verweisen)
- strong relationship b/w price + old price & b/w price + size (see )
- other relationships aren't strong


### Step 7: Interactions
- Coplotting designer and name works, while the two combination would not plot
- The linear model predicted infinite values and thus coplot the values properly for the other two options
- However, dropping all NA values and thus reducing the total data size to 354 observations would case for the combination coplot name and category while name + designer combination would not work
- The authors hypothesized that infinite values were caused by a division of zeros of the linear model since there occured 0 values in size
- This however proved to be wrong after applying respective filters

- The following interaction could be analyzed
- - There is probably no significant interaction between size, price, name & designer as can be seen in coplot -> lines are nearly parallel
- Based on the coplot of category and name with the 354 observations, inparallelity could be observed and thus could conclude a interaction. However, this could also be due to the small sample size 
-  


(footnote): the authors would highly appreciate any solutions on this matter



### Step 8: Independence of Price
- Durch das tidying in (cross reference) duplicate removal -> Zuur paper Step 8 1. citation: meaning that information from any one observation should not provide information on another after the effects of other variables have been accounted for. This concept is best explained with examples.


## Random Forest Regression Model {#random_forest_model}
- We chose rf
- random forest erklären -> article (for in depth reference see article)
- why random forest (not lm)? -> article to explain why random forest is great to explain feature importance
  - see article 
  - TODO: is normal distribution relevant for random forest (step 3) -> see article or site something
  
- To reproduce our results... (@Johannes)
  - We chose randomForest R package for our analysis -> as in ... (cite article)
  - data base is tidy ikea (step ...)
  - then transform this data set to apply rf (johannes)
    - remove old price because of high correlation factor (step 5 + 6) which would fuck up our overall result
    - fct_lump erklären
    - rf has problems with na values -> 3 different methods to solve problem -> calculated 3 feature importances -> mean(a, b, c) 



















<!--chapter:end:03-methods.Rmd-->

---
output:
  bookdown::pdf_document2:
    template: templates/brief_template.tex
  bookdown::word_document2: default
  bookdown::html_document2: default
documentclass: book
bibliography: references.bib
---

# Results {#results}

- x-reference theoretical background: rf / variable importance
- describe plot comprehensively  -- w/ numbers from table

<!--chapter:end:04-results.Rmd-->

---
output:
  bookdown::html_document2: default
  bookdown::word_document2: default
  bookdown::pdf_document2: 
    template: templates/brief_template.tex
documentclass: book
bibliography: references.bib
---
  
# Discussion {#discussion}

## size_m3

- material cost
- big items more expensive than small ones
- high correlation to price


## designer

- designers with high number of products produce products in wide price range : plot reference -> appendix

- many different combinations of designer (49-53)
- many designer-combinations with low number of products:
  - n combinations with occurrences<5

-> overfitting: cite scholarly article
-> low generalization : model might perfom bad on other data

## name

- overfitting

## category

- beds are more expensive than chairs : some categories are more expensive than others (show plot)
- but, price range varies heavily in category (show plot)

## other_colors

- products of every price range have both options : low importance
- mean price is higher if other_colors is true (show plot covariance price+other_colors)
- interquartile-range is smaller if other_colors is false

## sellable_online

sellable true: price range too high
sellable ntrue: very rare

## Conclusion & Ausblick

- Further research:
    - analyze designer overfitting, recommend using overfitting techniques (e.g. ...)
    - analyze same research question with other techniques (lm, name more) and compare
    - data scraping from other country-pages











<!--chapter:end:05-discussion.Rmd-->

---
#########################################
# options for knitting a single chapter #
#########################################
output:
  bookdown::html_document2: default
  bookdown::word_document2: default
  bookdown::pdf_document2:
    template: templates/brief_template.tex
documentclass: book
bibliography: references.bib
---

# Individual Statements

## Philip Krück

## Johannes Pein

<!--chapter:end:06-individual-statements.Rmd-->

`r if(knitr:::is_latex_output()) '\\startappendices'`

`r if(!knitr:::is_latex_output()) '# (APPENDIX) Appendix {-}'` 

<!-- If you feel it necessary to include an appendix, it goes here. The first appendix should include the commands above. -->


# Plots

## Plot xyz

## Plot abc



# Another Appendix

<!--chapter:end:front-and-back-matter/98-appendices.Rmd-->

