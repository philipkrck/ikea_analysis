---
#####################
## thesis metadata ##
#####################
title: Analyzing the Feature Importance of Different Variables on the Price of Ikea Products
author: Philip Krück, Johannes Pein
degree: B.Sc. Business Informatics (18A-BI)
degreedate: 04.12.2020
lecturer: "Lecturer: Ulf Köther"
groupnumber: "Group Number: 7"
modulename: "Digital Toolbox: Data Business"
matriculationnumbers: "Matriculation Numbers: 3938 (P.Krück), 4001 (J.Pein)"
abbreviations: "front-and-back-matter/abbreviations" # path to .tex file with abbreviations

#######################
## bibliography path ##
#######################
bibliography: references.bib
bibliography-heading-in-pdf: Works Cited

#####################
## PDF formatting  ##
#####################
abstractseparate: false  # include front page w/ abstract for examination schools?
bib-humanities: true   #set to true if you want in-text references formatted as author-year
doi-in-bibliography: true #set to true if you want DOI's to be shown in the bibliography
draft: false # add as DRAFT mark in the footer?
page-layout: nobind #'nobind' for PDF output (equal margins), 'twoside' for two-sided binding (mirror margins and blank pages), leave blank for one-sided binding (left margin > right margin)
hidelinks: true #if false, the PDF output highlights clickable links with a colored border - you will probably want to set this to true for PDF version you wish to physically print
toc-depth: 2 # depth of heading to include in table of contents
lof: true # list of figures in front matter?
lot: true # list of tables in front matter?
mini-toc: fase  # mini-table of contents at start of each chapter? (this just prepares it; you must also add \minitoc after the chapter titles)
mini-lot: false  # mini-list of tables by start of each chapter?
mini-lof: false  # mini-list of figures by start of each chapter?

params:
  corrections: true # set false to stop applying blue background to blocks of corrections

#####################
## output options  ##
#####################
output:
  bookdown::pdf_book:
    template: templates/template.tex
    keep_tex: true
    citation_package: default  
    pandoc_args: ["--lua-filter=scripts_and_filters/correction_filter.lua","--csl", "chicago_footnote.csl"] #remove filter to stop applying blue background to inline corrections
    extra_dependencies: ["float"]
  bookdown::gitbook:
    css: templates/style.css
    config:
      sharing:
        facebook: false
        twitter: yes
        all: false
  bookdown::word_document2:
    toc: true   
link-citations: true
documentclass: book
---

```{r create_chunk_options, include=FALSE, eval=knitr::is_latex_output()}
source('scripts_and_filters/create_chunk_options.R')
source('scripts_and_filters/wrap_lines.R')
```

``` {r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(readr)
ikea <- read_delim("ikea.csv", ";", 
                   escape_double = FALSE, 
                   trim_ws = TRUE,
                   col_types = cols(
                     name = col_factor(),
                     category = col_factor(),
                     designer = col_factor()
                   )
                  )

# tidy data

## tidy designer
tidy_ikea <- ikea

tidy_ikea$designer[grepl("\\d",tidy_ikea$designer)] <- NA


tidy_ikea <- tidy_ikea %>%
  separate(designer, c("d1", "d2", "d3", "d4", "d5", "d6", "d7"), sep = "/")

tidy_ikea[ , 11:17][tidy_ikea[ , 11:17] == "IKEA of Sweden" ] <- NA
tidy_ikea[ , 11:17] <- t(apply(tidy_ikea[ , 11:17], 1, function(x) c(sort(x[x!='']), x[x==''])))

tidy_ikea <- tidy_ikea %>%
  unite(col = "designer", d1, d2, d3, d4, d5, d6, d7, sep = ", ", na.rm = TRUE)

tidy_ikea$designer[tidy_ikea$designer == ""] <- NA

## convert other colors to boolean
tidy_ikea <- tidy_ikea %>%
  mutate(other_colors = other_colors == "Yes")

## convert old price to integer and times 10
tidy_ikea <- tidy_ikea %>%
  mutate(old_price = str_replace(old_price, "SR ", "")) %>%
  mutate(old_price = str_replace_all(old_price, ",", "")) %>%
  mutate(old_price = strtoi(old_price)) %>%
  mutate(old_price = old_price * 10)
  
# transform data columns

# add size in m^3
tidy_ikea <- tidy_ikea %>%
  mutate(size_m3 = round(depth/100 * width/100 * height/100, 2))

# transform price and old price in eur
sr_to_eur_conversion_factor <- 0.24537 # conversion factor from 20.04.2020 (https://www.xe.com/de/currencyconverter/convert/?Amount=1&From=EUR&To=SAR)

tidy_ikea <- tidy_ikea %>%
  mutate(price_eur = round(price * sr_to_eur_conversion_factor / 10, 2), old_price_eur = round(old_price * sr_to_eur_conversion_factor / 10, 2))

## select relevant data
tidy_ikea <- tidy_ikea %>%
  select(name, category, price_eur, old_price_eur, sellable_online, other_colors, designer, size_m3)
```

``` {r echo=FALSE, message=FALSE}
# setup color theme
library('RColorBrewer')
num_cols <- 17
mycolors <- colorRampPalette(brewer.pal(12, "Set3"))(num_cols) # add a custom color palette
```

<!--chapter:end:index.Rmd-->

---
#########################################
# options for knitting a single chapter #
#########################################
output:
  bookdown::html_document2: default
  bookdown::word_document2: default
  bookdown::pdf_document2:
    template: templates/brief_template.tex
documentclass: book
bibliography: references.bib
---

# Introduction {#intro}

This project report is an examination at the Hamburg School of Business Administration in the module 'Data Business' as a part of a Bachelor of Science degree program. The students were given a data set and the task was to first explore the data and then choose a research question which was to be answered scientifically with the help of the statistical programming language R. The authors of this report were given a data set which contains Ikea products with different features, such as price, dimensional measures, name, category and designers of the product.

<!--chapter:end:01-introduction.Rmd-->

---
#########################################
# options for knitting a single chapter #
#########################################
output:
  bookdown::html_document2: default
  bookdown::word_document2: default
  bookdown::pdf_document2:
    template: templates/brief_template.tex
documentclass: book
bibliography: references.bib
---

# Theoretical Background & Research Question  {#chapter-2}

## Data Set
\textcolor{gray}{by P. Krück}

The data set was obtained by a kaggle.com user (Reem Abdulrahman) by the means of webscraping techniques from the Saudi Arabian Ikea website in the furniture category on the 20th of April 2020. Noteworthy features include the name, category, price in Saudi Riyals, the designer and dimensions (width, height and depth). 
The data set has 13 variables and 2962 distinct observations after the removal of duplicates.

## Theoretical Background {#theoretical-background}

### Random Forest Basics
\textcolor{gray}{by J. Pein}

In order to analyze the feature importance in relation to the price variable, a random forest regression model was chosen. A random forest consists of many decision trees, which predicts the response variable based on a majority decision process. In standard decision trees, each node is split to achieve the best performing model. In random forests however, the nodes are randomly split. 
Compared to linear regression, random forests not only take the mean and covariance structure into account, but also include deeper aspects of the data [@Groemping2009, p.317] resulting in a more advanced and robust model. To learn more about random forests, please see @Breiman2001. 

### Overfitting {#overfitting}
\textcolor{gray}{by P. Krück}

In statistical modelling, overfitting refers to the phenomenon where an analysis model corresponds to closely to a given data set and thus fails to generalize to new data or future observations.


### Feature Importance {#feature-importance}
\textcolor{gray}{by J. Pein}

There are different ways to measure feature importance. In this analysis permuting feature importance by a random forest algorithm is used. This algorithm leaves each feature out once while leaving all others unchanged, at each step calculating the mean squared error (MSE) of the predictions. This is done for every tree, calculating the overall MSE of each feature for the whole model [@Breiman2001, p.23].


## Research Question {#research-question}
\textcolor{gray}{by P. Krück}

This paper explores the following research question:

*How important are the different features of Ikea products in regard to their price?*

The motivating forces for this research question are the possible implications for price determination of new items.


<!--chapter:end:02-background-research-question.Rmd-->

---
output:
  #bookdown::html_document2: default
  #bookdown::word_document2: default
  bookdown::pdf_document2:
    template: templates/brief_template.tex
documentclass: book
bibliography: references.bib
---

# Methods {#methods}


## Data Cleaning and Transformation {#datacleaning}
\textcolor{gray}{by P. Krück}

To examine the given data set properly, the authors first had to restructure and reformat it. This initial data cleaning step included type conversion, value mutation, addition of newly calculated fields and the removal of irrelevant columns.

Concretely, ```name```, ```category``` and ```designer``` were converted to categorical variables. In the ```designer``` column, blank strings and values prefixed by “IKEA of Sweden” were converted to missing values (```NA```). Furthermore, both the price and old price were converted to double values and the currency was changed from Saudi Arabian Riyals to Euros based on the exchange rate from the time the data set was obtained by the author (See section \@ref(theoretical-background)).

Interestingly, the data set had a peculiarity where some rows were exact duplicates except for values in the ```category``` vector. The authors considered multiple approaches to handle these data duplications without losing information about the category of an item. 

One considered option was to merge the two category values into one column value via comma separation (e.g. ```"a"``` and ```"b"``` converts to ```"a, b"```). However, this approach leads to the creation of many combinatorial categories with a low count of items per category.
Additionally, it reduces the item count per category where the category is not comma separated.
Overall this would lead to having many small categories which increases the difficulty in applying a regression model due to overfitting (See section \@ref(overfitting)).

The second option was to create separate columns for the different values of ```category```. The data set would then have observations with category one, two and three. While no information is lost utilizing this approach, most observations in the second and third category column would contain missing values, thus increasing the difficulty of analysis using a predefined model (See section \@ref(rf)).

The authors chose the option of selecting the observations where the category count occurred most frequently when considering duplicates. The most frequent categories could be retained without including more column vectors into the data set as in option two.

To better facilitate the comparison of the different sizes of furniture items, the size in cubic meters was computed based on the depth, width and height values, and added as a column vector for further analysis. 

Finally, the authors only selected columns that could have a potential impact on outcome of the analysis (See section \@ref(research-question)) for further investigation. A detailed comparison of the initial vs. transformed data structure can be seen in tables \@ref(tab:initial-ikea) and \@ref(tab:tidy-ikea).

```{r initial-ikea, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE,}
library('kableExtra')
library(tidyverse)
library(modelr) 
library(broom) 
library(GGally) 
library(gridExtra) 

output_table <- data.frame(lapply(tail(ikea), as.character), stringsAsFactors = FALSE) %>%
  select(name, category, price, old_price, sellable_online, other_colors, designer) %>%
  mutate(name = str_trunc(name, 6), designer = str_trunc(designer, 8), `...` = c("...", "...", "...", "...", "...", "..."))

knitr::kable(output_table, caption = "Initial Data Set formatting.") %>%
  kable_styling(font_size = 8, position = "center")
```

```{r tidy-ikea, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE,}
output_table_two <- data.frame(lapply(tail(tidy_ikea), as.character), stringsAsFactors = FALSE) %>%
  mutate(name = str_trunc(name, 6), designer = str_trunc(designer, 8))

knitr::kable(output_table_two, caption = "Transformed Data Set formatting.") %>%
  kable_styling(font_size = 8, position = "center")
```



## Exploratory Data Analysis {#tbd}
\textcolor{gray}{by P. Krück}

The following sections explore our data based on the eight step data exploration protocol proposed by Zuur et al [@Zuur2010]. 


### Step 1: Outliers in Price and Independent Variables {#outliers}
\textcolor{gray}{by P. Krück}

Outliers of the chosen variables can be observed for each variable (see figure \@ref(fig:outliers)). 
Web scraping code is written in a generic form which makes it generalizable to all applied pages. This removes the occurance of observation errors in the Ikea data set. Additionally, it is also unlikely that the outliers are due to falsely scraped items.
To verify this hypothesis, the authors randomly tested outlier observations and manually checked them against the ikea website information. With a high level of statistical confidence, the authors proceeded with further analysis without removing outliers as observation errors.


```{r, outliers, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, fig.cap="Boxplots for Price in € based on Independent Variables", out.width="100%"}
## Boxplots for all factor variables against the DV (hwy):
p1 <- ggplot(tidy_ikea, aes(x = fct_lump(name, 8), y = price_eur)) + geom_boxplot(outlier.alpha = 0.3) + coord_flip() + ylab("") + xlab("name")
p2 <- ggplot(tidy_ikea, aes(x = fct_lump(category, 8), y = price_eur)) + geom_boxplot(outlier.alpha = 0.3) + coord_flip() + ylab("") + xlab("category")
p3 <- ggplot(tidy_ikea, aes(x = sellable_online, y = price_eur)) + geom_boxplot(outlier.alpha = 0.3) + coord_flip() + ylab("") + xlab("sellable online")
p4 <- ggplot(tidy_ikea, aes(x = other_colors, y = price_eur)) + geom_boxplot(outlier.alpha = 0.3) + coord_flip() + ylab("") + xlab("other colors")
p5 <- ggplot(tidy_ikea, aes(x = fct_lump(designer, 8), y = price_eur)) + geom_boxplot(outlier.alpha = 0.3) + coord_flip() + ylab("") + xlab("designer")
## Plot all ggplot objects together (gridExtra):
grid.arrange(p1, p2, p3, p4, p5, nrow = 3)
```

### Step 2: Homogeneity of Price
\textcolor{gray}{by P. Krück}

The homogeneity (homoscedasticity) of variance for price is explored by the means of conditional boxplotting. 
Within each name, and within each category the variance is heterogenous (see fig. \@ref(fig:homogeneity)). However, looking at both name and category in conjunction, it is possible to explore homoscedasticity of variance for price.

Due to the limited scope and length of this paper, the authors were not able to inspect all variable combinations for the three categorical plus two logical variables of the data set($2^5=32$).


```{r, homogeneity, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, fig.cap="Homogeneity of category for selected combinations of name and category", out.width="100%"}
tidy_ikea %>%
  filter(name == "HEMNES" | name == "LIDHULT" | name == "VIMLE" | name == "VALLENTUNA" | name == "GRÖNLID") %>%
  filter(category == "Beds" | category == "Chairs" | category == "Sofas & armchairs") %>%
  ggplot(mapping = aes(x = reorder(name, price_eur), y = price_eur, color = name)) +
  geom_boxplot(width = 0.4, outlier.size = 0.5, outlier.alpha = 0.3, show.legend = FALSE) + 
  scale_color_manual(values = mycolors) +
  theme_minimal() +
  coord_flip() +
  labs(x = "name", y = "price in Euro", fill = "", subtitle = "category") +
  facet_grid(~ category)
```



### Step 3: Normality 
\textcolor{gray}{by P. Krück}

No numerical variables (```price```, ```old_price``` and ```size_m3```) are arranged along a normal distribution (see fig. \@ref(fig:normality)), but rather follow an exponential decay ($e^{-x}$).


```{r, normality, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, fig.cap="Histogram of Numerical Variables with a Bin Width of 100 Euro", out.width="100%"}
tidy_ikea %>%
  select(where(is.numeric)) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "num") %>% group_by(variable) %>%
  arrange(num) %>%
  mutate(observation = 1:n()) %>%
  ungroup() %>%
  ggplot(aes(x = num)) + theme_bw() +
  geom_histogram(bins = 100) + facet_wrap(~ variable, scales = "free") + ylab("") + xlab("")
```



### Step 4: Missing Values {#missing-values}
\textcolor{gray}{by P. Krück}

All variables were examined for missing values. Only ```designer```, ```size_m3``` and ```old_price_eur``` have missing values with percentages of 3.44%, 45.9% and 81% respectively (see fig. \@ref(fig:missing-values)). 
The missing values for designer were deliberately set to ```NA``` by the authors in the case where the values contained digits, which is likely a scraping error. 
The ```NA``` values for the size can be explained due to the computation of this column vector. ```size_m3``` is the product of ```depth```, ```width``` and ```height```. If one of those three values is missing, the end result is also a missing value. 
In contrast, the abscence of the old price variables is due to the fact that most items are not on sale and thus do not have a missing value.

```{r, missing-values, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, fig.cap="Percentage of missing values", out.width="100%"}
missing_values <- tidy_ikea %>%
  gather(key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  group_by(key) %>%
  mutate(total = n()) %>%
  group_by(key, total, isna) %>%
  summarise(num.isna = n()) %>%
  mutate(pct = num.isna / total * 100)
## `summarise()` regrouping output by 'key', 'total' (override with `.groups` argument)
levels <-
  (missing_values  %>% filter(isna == T) %>% arrange(desc(pct)))$key

missing_values %>%
  ggplot() +
  geom_bar(aes(x = reorder(key, desc(pct)), 
               y = pct, fill=isna), 
           stat = 'identity', alpha=0.8) +
  scale_x_discrete(limits = levels) +
  scale_fill_manual(name = "", 
                    values = c('steelblue', 'tomato3'), labels = c("Present", "Missing")) +
  coord_flip() +
  labs(x =
         'Variable', y = "% of missing values")
```


### Step 5: Collinearity between Independent Variables {#collinearity}
\textcolor{gray}{by P. Krück}

The old price has a rather high variance inflation factor (VIF) which corresponds to high multicollinearity (see table \@ref(tab:vif)). Contrarily, size has a low VIF which translates to low multicollinearity among the other independent variables (see table \@ref(tab:vif)).

```{r vif, echo=FALSE}
library('kableExtra')

vif <- data.frame(
  `price_eur` = 77.97,
  `old_price_eur` = 78.54,
  `size_m3` = 2.36
)

knitr::kable(vif, caption = "Variance Inflation Factors for Numerical Variables")
```



### Step 6: Relationship between Independent Variables and Price {#relationship}
\textcolor{gray}{by P. Krück}

Inspecting the relationship between the independent variables and price, a strong correlation between ```old_price_eur``` and ```size_m3``` can be observed, while none can be detected for the other variables (see \@ref(fig:relationship-x-y)).
```old_price_eur``` has a linear relationship (see fig. \@ref(fig:relationship-old-price)) whereas ```size_m3``` begins with a linear relationship as well, which is only disturbed by an outlier.  (see fig. \@ref(fig:relationship-size-m3)).


```{r relationship-old-price, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, fig.cap="Relationshihp of Price and Old Price", out.width="100%"}
tidy_ikea %>%
  filter(!is.na(old_price_eur)) %>%
  ggplot(aes(x = old_price_eur, y = price_eur)) +
    geom_point(color = mycolors[1], alpha = 0.5) +
    geom_smooth(color = mycolors[5], se = FALSE) +
    theme_minimal() +
    labs(x = "old price in Euro", y = "price in Euro")
```

```{r relationship-size-m3, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, fig.cap="Relationship of Price Size in Cubic Meters", out.width="100%"}
tidy_ikea %>%
  filter(!is.na(size_m3)) %>%
  ggplot(aes(x = size_m3, y = price_eur, colour = "red")) +
    geom_point(alpha = 0.3, show.legend = FALSE) +
    geom_smooth(show.legend = FALSE, color = "orange", fill = "orange", alpha = 0.25) +
    scale_color_manual(values = mycolors) +
    theme_minimal() +
    labs(x = "size in m^3", y = "price in Euro")
```

### Step 7: Interactions
\textcolor{gray}{by P. Krück}

The interactions between different variables are explored by the use of conditioning plots (coplots).
Using this form plotting the relationship of two numerical variables is explored by creating a matrix of plots subdivided by two categorical variables. 
In the given data set there are three numerical and three categorical variables which can be explored in this form of interaction. For the numerical variables, ```old_price_eur``` has such a strong relationship with ```price``` (see fig \@ref(fig:relationship-old-price)). A more detailed breakdown by the categorical variables would not reveal new information. This leaves the exploration of ```size_m3``` and ```price_eur``` subdivided by designer, name and category resulting in (${3 \choose 2} = 3$) combinations of coplots.

#### Interaction of size and price coplotted by designer and name {#size-price-interaction}
\textcolor{gray}{by P. Krück}

It is unlikely that there is an interaction between size and price split by name and designer as is indicated by the non-parallelism of the fitted lines in the coplot (see figure \@ref(coplot-code-designer-name)).


#### Problems with Coplot Development
\textcolor{gray}{by P. Krück}

This section describes a programming error the authors ran into regarding coplotting.

Unfortunately, the authors of this papers weren't able to fully explore all combinations.
Plotting designer and name works (see section \@ref(size-price-interaction)) while the other two options would not plot properly. 
The authors could not fully debug the problem with these plots.
The linear model predicted infinite values for some of the coplotted combinations for both amalgamations that wouldn't render correctly. 
Dropping all ```NA``` values left 354 observations and the coplot would correctly render for the combination of ```name``` and ```category``` while for ```name``` and ```designer``` it would not. The number of observations for ```name``` and ```category``` is rather low considering the additional categorical subdivision which lead the authors to discard it as an insignificant research finding.
Still there seemed to be infinite values outputted by the linear method. The authors hypothesized that those values were caused by a division by 0 of the internal algorithm mechanics. This however proved to be wrong after applying the respective filters.
The code for the 3 plots can be viewed in Appendix chapter \@ref(coplots).

The inclined reader is encouraged to dabble with the code. Sending any hints or even a solution to fix the code and fully render the plots would be highly appreciated by the authors.
^[Any questions, hints or solutions may kindly be sent to philip.krueck\@myhsba.de.]



### Step 8: Independence Observations of Response Variable Price
\textcolor{gray}{by P. Krück}

The independence of observerations of the response variables assumes that "[...] information from any one observation should not provide information on another after the effects of other variables have been accounted for" [@Zuur2010, p.11, ll. 23-26].
The data cleaning step left the observed data set in a tidy format which implies that the observations are independent of eachother.
^["There are three interrelated rules which make a dataset tidy: Each variable must have its own column. Each observation must have its own row. Each value must have its own cell." ([@Hadley2017, p.149, ll. 4-7])]


## Random Forest Regression Model {#rf}
\textcolor{gray}{by J. Pein}


To analyze the feature importance of different variables on the price variable, a random forest model was chosen. In the given data set, categorical variables with lots of different values can be observed. Including all of those values in, for example, a linear regression model, would most likely lead to overfitting (see section \@ref(overfitting)). This is because the linear model would learn the immanent data structure of the sample, but would not be able to generalize from this. Thus, the authors chose the random forest model, because according to @Breiman2001[p.29] it is robust against overfitting.

In this analysis, the R _randomForest_ package was used, which is based on the original Breiman and Cutler's Fortran code for random forest regression. To reproduce the results, the further data preparation steps are described here. These steps are based on the cleaned ikea data set which is described in section \@ref(datacleaning). This data set is then transformed further allowing it to be used with the _randomForest_ package. To learn more about how random forests work see chapter \@ref(chapter-2), to learn more about the _randomForest_ package see @Liaw2002. 

First, the variable `old_price_eur` is removed from the cleaned ikea data set, due to a very high correlation and relationship to the response variable `price_eur` (price) analyzed in section \@ref(collinearity) and section \@ref(relationship). Then, the `designers` and `names`, which are not part of the 50 `designers` and 49 `names` with the highest number of occurences, are grouped in the `other` value. This is because the `randomForest` method does not allow categorical variables with more than 53 predictors. The last step deals with the missing values in the data. As described in section \@ref(missing-values), there are many missing values in the `size_m3` and `designer` variables. To apply the `randomForest` method of the _randomForest_ package on the data, those missing values are treated using three different approaches. In the first approach the rows with missing values are deleted, reducing the total number of rows by aproximately 50%. In the second approach the missing values are dummy coded with a value of -1000. The third approach uses the `na.roughfix = na.omit` argument, which is the built-in way of the _randomForest_ package to deal with missing values.
After preparing the data, the `randomForest` method of the _randomForest_ package is applied to the data with number of trees set to 2000 and importance set to `TRUE`, training the random forest model with the prepared ikea data set.

`randomForest(price_eur ~ ., rf_ikea, ntree=2000, importance=TRUE)`

Then the `importance` method of the _randomForest_ package is used to calculate the feature importances, which are computed by permuting feature importance, which was introduced in section \@ref(feature-importance). The three different approaches of dealing with the missing values in the data set lead to different results, so the authors chose to calculate the mean result of the three approaches. The result of this analysis is presented in the following chapter.


















<!--chapter:end:03-methods.Rmd-->

---
output:
  bookdown::pdf_document2:
    template: templates/brief_template.tex
  bookdown::word_document2: default
  bookdown::html_document2: default
documentclass: book
bibliography: references.bib
---

```{r echo = FALSE, warning = FALSE, message = FALSE, results = 'hide'}
library(randomForest)
library(ggplot2)

tidy_ikea # make sure that tidy.R is executed and tidy_ikea is loaded into memory

###############
## ANALYSIS ###
###############

n_trees <- 10

#TODO: set to 2000 before handing in

# correlation price + old_price

cor.test(tidy_ikea$price_eur, tidy_ikea$old_price_eur, 
         method = "pearson")

# importance - drop_na

rf_ikea <- tidy_ikea %>%
  select(-old_price_eur) %>%
  drop_na()

rf_ikea$designer <- fct_lump_n(rf_ikea$designer, 50)
rf_ikea$name <- fct_lump_n(rf_ikea$name, 49)

result_rf <- randomForest(price_eur ~ ., rf_ikea, ntree=n_trees,
                          keep.forest=FALSE, importance=TRUE)
imp_drop_na <- importance(result_rf)

# importance - dummy value instead of na

rf_ikea <- tidy_ikea 

rf_ikea$size_m3[is.na(rf_ikea$size_m3)] <- -1000

rf_ikea <- rf_ikea %>%
  select(-old_price_eur) %>%
  drop_na()

rf_ikea$designer <- fct_lump_n(rf_ikea$designer, 50)
rf_ikea$name <- fct_lump_n(rf_ikea$name, 49)

result_rf <- randomForest(price_eur ~ ., rf_ikea, ntree=n_trees,
                        keep.forest=FALSE, importance=TRUE)
imp_size_minus_1000 <- importance(result_rf)


# importance - na roughfix

rf_ikea <- tidy_ikea %>%
  select(-old_price_eur)

rf_ikea$sellable_online <- factor(rf_ikea$sellable_online)
rf_ikea$other_colors <- factor(rf_ikea$other_colors)

rf_ikea$designer <- fct_lump_n(rf_ikea$designer, 50)
rf_ikea$name <- fct_lump_n(rf_ikea$name, 49)

result_rf <- randomForest(price_eur ~ ., rf_ikea, ntree=n_trees, importance=TRUE, na.action = na.roughfix)
imp_na_roughfix <- importance(result_rf)


# mean importance

mean_imp <- as.data.frame((imp_na_roughfix+imp_size_minus_1000+imp_drop_na)/3)

mean_imp$varnames <- rownames(mean_imp)
rownames(mean_imp) <- NULL
mean_imp <- mean_imp %>%
  rename('PercentIncMSE' = '%IncMSE')
```

# Results {#results}
\hfill\textcolor{gray}{by J. Pein}

## TODO: set n_trees to 2000 before handing in

In this chapter, the result of the analysis of the feature importance of different features on the response variable price of Ikea products are presented.

As described in section \@ref(rf), the feature importance was calculated using permuting feature importance of the _randomForest_ R package. In this analysis, feature importance is derived from the percentage increase of the mean squared error (MSE) of the overall random forest regression model in regard to the response variable `price_eur`. A larger percentage increase of the MSE implies greater feature importance. Conversely, a lower percentage increase of the MSE translates to less  feature importance.

```{r mean-feature-importance, echo=FALSE, out.width="100%", fig.cap="A Plot Showing the Mean Feature Importance of the Predictor Variables on the Response Variable"}
ggplot(mean_imp, aes(y=reorder(varnames, PercentIncMSE), x=PercentIncMSE)) + 
  geom_point() +
  scale_color_manual(values = mycolors) +
  theme_minimal() +
  labs(x = "% Increase MSE", y = "Feature", title = "Mean Feature Importance")
```


Thus, as can be seen in figure \@ref(fig:mean-feature-importance), the most important feature is `size_m3`  with an increase of the MSE of 182%. The second, third and fourth most important features are `designer` with an MSE increase of 120%, `name` with an increase of 114% and `category` with an increase of 105%. The fifth most important feature is `other_colors` with a MSE increase of 78% and the least important feature is `sellable_online` with a 9% increase.

These results are further discussed in the following chapter.




<!--chapter:end:04-results.Rmd-->

---
output:
  bookdown::html_document2: default
  bookdown::word_document2: default
  bookdown::pdf_document2: 
    template: templates/brief_template.tex
documentclass: book
bibliography: references.bib
---
  
# Discussion {#discussion}
\hfill\textcolor{gray}{by J. Pein}

In this chapter, the results are discussed in connection with the research question. The question that the results were supposed to answer is the following:

*How important are the different features of Ikea products in regard to their price?*

## Feature Importance

The `size_m3` variable is the most important feature. Probably the main reason for this is the size of a product being closely linked to its material cost. Big items are generally more costly to produce, thus leading to a higher selling price and vice versa. Due to the high correlation to the price variable described in section \@ref(collinearity) and section \@ref(relationship), it is worth discussing in future research whether or not to include this variable in a possible predictive analysis model . 

The `designer` variable is the second most important feature. When looking at the price distribution per designer, in can be clearly seen that the interquartile range (IQR) of price varies for each designer. In addition, the IQR often is smaller than 300€, thus showing a tendency towards a certain price range, which might be the reason for the relatively high feature importance of the designer variable. For the plot, see figure \@ref(fig:price-dist-per-designer).

The `name` variable includes around 50 different product names with partly small numbers of occurences. But, as can be seen in figure \@ref(fig:homogeneity), certain product lines (names) tend to be more expensive than others. *LIDTHULT*, for example, is the most expensive product line in each of the categories *beds*, *chairs* and *sofas & armchairs* while *HEMNES* is on the lower end of the price scale. This behavior explains a relatively high feature importance of the `name` variable.

`Category` is another feature with a relatively high importance. One reason for this is the different category's price distributions showing a clear tendency towards certain price segments (see figure \@ref(fig:price-dist-per-category)), i.e. wardrobes and beds are generally more expensive than chairs.

The feature importance of `other_colors` is the second lowest, but still considerable. This still relatively high feature importance might be due to the difference of the mean price and the relatively small IQR (see: figure \@ref(fig:price-dist-other-colors)). On the other hand, there is a large overlapping area within the IQR in the two expressions of `other_colors` possibly reducing the feature importance.

The very low feature importance of the `sellable_online` variable is probably because the low number of occurences of a product being sellable online. Only around 0.6% of the products are sellable online.

## Conclusion

The data used in this paper was scraped from the Saudi Arabian Ikea website, thus this analysis mainly focusses on Ikea products in the Saudi Arabian market. To analyze the geographically independent feature importances, more data should be scraped from other international Ikea websites. The research question of this paper, *How important are the different features of Ikea products in regard to their price?*, could thus not be answered for the global Ikea product market, but for the Saudi Arabian market only.

Also, in further research, the results presented on the feature importance of the predictor variables on the response variable price should be validated by other techniques than the random forest model used in this analysis to achieve unbiased results. 

Furthermore, based on this analysis a predictive model could be developed which predicts the price of Ikea products in the Saudi Arabian Market based on the features analyzed. This could be used by Ikea internally to analyze if the price of their new product aligns with the prices of the currently available product or by market researchers. 

Lastly, the authors were surprised by the high feature importances of the variables `designer` and `name` computed by the random forest model. Both variables have lots different values, suggesting an overfitting of the random forest model. This, however, is objected by scientific research [@Breiman2001, p.29].
Exploring what the reason behind the high feature importances of the variables `designer` and `name` and if they are due to overfitting of a random forest model should be analyzed in future research. 
If the high feature importance of the variables truly is not due to overfitting, this example backs up the thesis of @Groemping2009[p.317] that random forests are able to discover deeper patterns in the data. These patterns are beyond the discussion applied here, showing the power of random forests models.










<!--chapter:end:05-discussion.Rmd-->

`r if(knitr:::is_latex_output()) '\\startappendices'`

`r if(!knitr:::is_latex_output()) '# (APPENDIX) Appendix {-}'` 

<!-- If you feel it necessary to include an appendix, it goes here. The first appendix should include the commands above. -->


# Appendix

```{r price-dist-per-designer, echo = FALSE, warning = FALSE, message = FALSE, results = 'hide', fig.cap="A Plot Showing the Price Distribution per Designer", out.width="100%"}
tidy_ikea %>%
  ggplot(mapping = aes(x = fct_reorder(fct_lump(tidy_ikea$designer, 25), price_eur), y = price_eur, colour = fct_lump(tidy_ikea$designer, 25))) +
    geom_boxplot(width = 0.4, outlier.size = 0.5, outlier.alpha = 0.3,  show.legend = FALSE) +
    theme_minimal() +
    labs(x = "", y = "price in Euro", fill = "") +
    coord_flip()
```


```{r price-dist-per-category, echo = FALSE, warning = FALSE, message = FALSE, results = 'hide', fig.cap="A Plot Showing the Price Distribution per Category", out.width="100%"}
tidy_ikea %>%
  ggplot(aes(x = reorder(fct_lump(tidy_ikea$category, 15), price_eur), y = price_eur, colour = fct_lump(tidy_ikea$category, 15))) +
    geom_boxplot(width = 0.4, outlier.size = 0.5, outlier.alpha = 0.3,  show.legend = FALSE) +
    scale_color_manual(values = mycolors) +
    theme_minimal() +
    labs(x = "", y = "price in Euro", fill = "") +
    coord_flip()
```


```{r price-dist-other-colors,echo = FALSE, warning = FALSE, message = FALSE, results = 'hide', fig.cap="A Plot Showing the Price Distribution Other Colors", out.width="100%"}
knitr::opts_chunk$set(fig.pos = '!h')

tidy_ikea %>%
  ggplot(aes(x = price_eur, y = other_colors, color = other_colors)) +
  geom_boxplot(width = 0.4, outlier.size = 0.5, outlier.alpha = 0.3,  show.legend = FALSE) +
  scale_color_manual(values = mycolors) +
  theme_minimal() +
  labs(x = "price in Euro", y = "other_colors", fill = "")
```

```{r price-dist-sellable-online,echo = FALSE, warning = FALSE, message = FALSE, results = 'hide', fig.cap="A Plot Showing the Price Distribution Sellable Online", out.width="100%"}
tidy_ikea %>%
  ggplot(aes(x = price_eur, y = sellable_online, color = sellable_online)) +
    geom_boxplot(width = 0.4, outlier.size = 0.5, outlier.alpha = 0.3,  show.legend = FALSE) +
    scale_color_manual(values = mycolors) +
    theme_minimal() +
    labs(x = "price in Euro", y = "sellable_online", fill = "", title = "Price Distribution Sellable Online")
```

```{r relationship-x-y, echo = FALSE, warning = FALSE, message = FALSE, results = 'hide', fig.cap="Relationship between Independent Variables and Price", out.width="100%"}
tidy_ikea %>%
  mutate(across(where(is.character), as.factor)) %>% mutate(across(where(is.factor), as.numeric)) %>%
  # select() %>% # De-select variables here if necessary
  pivot_longer(-price_eur, names_to = "variable", values_to = "num") %>% group_by(variable) %>%
  arrange(num) %>%
  mutate(observation = 1:n()) %>%
  ungroup() %>%
  ggplot(aes(x = num, y = price_eur)) + theme_bw() +
  geom_point(shape = 1, alpha = 0.8, position = "jitter") +
  geom_smooth(se = FALSE, colour = "blue", method = "loess", formula = 'y ~ x') +
  facet_wrap(~ variable, scales = "free_x") + ylab("Price in Euro") + xlab("")
```




# Coplots {#coplots}

```{r coplot-code-designer-name, echo = FALSE, warning = FALSE, message = FALSE, eval = TRUE, fig.cap="Coplot of Size and Price Split by Designer and Name", out.width="100%",}
library('tidyr')

coplot(size_m3 ~ price_eur | fct_lump_n(designer, 5) + 
         fct_lump_n(name, 5), data = drop_na(tidy_ikea),
       ylab = c("Size in m^3", "Name"),
       xlab = c("Price in Euro", "Designer"), panel = function(x, y, ...) {
         tmp <- lm(y ~ x, na.action = na.omit)
         abline(tmp)
         points(x, y )})
```

```{r coplot-code-category-name, echo = TRUE, warning = FALSE, message = FALSE, eval = FALSE, cap="Code for Coplotting Combinations", out.width="100%"}
coplot(size_m3 ~ price_eur | fct_lump_n(category, 5) + 
         fct_lump_n(name, 5), data = drop_na(tidy_ikea), 
       ylab = "Size in m^3",
       xlab = "Price in Euro", panel = function(x, y, ...) {
         tmp <- lm(y ~ x, na.action = na.omit)
         abline(tmp)
         points(x, y )})
```

```{r coplot-code-designer-category, warning = FALSE, message = FALSE, eval = FALSE, cap="Code for Coplotting Combinations", out.width="100%"}
coplot(size_m3 ~ price_eur | fct_lump_n(designer, 5) + 
         fct_lump_n(category, 5), data = drop_na(tidy_ikea), 
       ylab = "Size in m^3",
       xlab = "Price in Euro", panel = function(x, y, ...) {
         tmp <- lm(y ~ x, na.action = na.omit)
         abline(tmp)
         points(x, y )})
```


# Bibliography














<!--chapter:end:front-and-back-matter/98-appendices.Rmd-->

