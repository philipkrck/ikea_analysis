---
output:
  #bookdown::html_document2: default
  #bookdown::word_document2: default
  bookdown::pdf_document2:
    template: templates/brief_template.tex
documentclass: book
bibliography: references.bib
---

# Methods {#methods}


## Data Cleaning and Transformatoin {#datacleaning}
To examine our data set properly, we first had to restructure and reformat it. This initial data cleaning step included type conversions, value mutation, addition of new calculated fields and the dropping of irrelevant columns.
Concretely, we converted name, category and designer to categorical variables. In the designer column, we converted blank strings and values prefixed by “IKEA of Sweden” to missing values (```NA```). Furthermore, we converted both the price and old price to double values and changed the currency from Saudi Arabian Riyals to Euros based on the exchange rate from the time the data set was obtained by the author \@ref(#theoretical_background). To better facilitate the comparison of the different sizes of furniture items, we calcuted the size in cubic meters based on the depth, width and height values. 
Finally, we selected only columns that could have a potential impact in our analysis (see Table \@ref(tab:initial-ikea) and \@ref(tab:tidy-ikea)).

tidy category -> duplicate filtering
- there were some observations with the same item id. All other value were the same in these instances except for the category. 
- The authors considered multiple approaches to handle these data duplications
- Option one -> mutate duplicates into one combination of categories (e.g. a and b to a, b), then the newly created categories would have a low count of observations while the single categories would have a decreased count. We would then have an increased count in categories. Because the count of the individual categories is low, no definite conclusion can be drawn for the interaction on the price
- Option two -> create multiple variables for each observed category for the same item id. The authors wanted to analyze the feature importance of category variable as such and not the multiple occurrences of the category variable
- The authors chose option of selecting the observations where the category count occurred most frequent.




TODO: Format these tables
```{r initial-ikea, echo=FALSE}
library('kableExtra')

knitr::kable(head(ikea), caption = "Initial Data Set formatting.")
```

```{r tidy-ikea, echo=FALSE}
knitr::kable(head(tidy_ikea), caption = "Data Set after cleaning process.")
```



## 8 Step EDA (nice heading) {#tbd}
[@Zuur2010, pp. 33-35].
- Our EDA analysis is based on the protocol for data exploration proposed by ZUUR paper
- This 8 step analysis is especially useful for regression models


### Step 1: Outliers in Price and Independent Variables
- Assumption: outliers are not by chance or random (no observer error)
- Assumption seems to hold up when looking at individual outlier observations. These are congruent in themselves. Assume: web scraping technique is highly unlikely to have measurement error ocurrence
- Use outliers in model

### Step 2: Homogeneity of Price
- To test the assumption of  homogeneity of variance for price (homoscedasticity) by the means of conditional boxplotting
- As can be seen, price is homogoneous for all category  variable except for beds where the variance differes widely (see plot xxx)
- price is heterogenous for all individual names by category (see plot xxx)
- Looking at both categories simultaneously -> homogenous
- Im Rahmen der Arbeit nicht möglich alle kategorischen Variablen Kombinationen anzuschauen. 5 kategorische Variablen -> 2^5 = 32 Möglichkeiten


### Step 3: Missing Value Trouble
- not normal verteilt
- ikea ist im Niedrigpreissegment angesiedelt
- see figure ....
- exponential decay in price, old price and size (e^-x)


### Step 4: Zeros
- many missing values from old price -> assume those were not on sale
- size_m3 missing values because of calculation formula
- designer -> removed values containing digits (were clearly falsely scraped)



### Step 5: Collinearity between Independent Variables
- high collinearity between old price and price
- relatively high collinearity between price and size
- as can be seen in table


### Step 6: Relationship between Independent Variables and Price
- from eda_covariance.Rc (in Anhang + verweisen)
- strong relationship b/w price + old price & b/w price + size (see )
- other relationships aren't strong


### Step 7: Interactions
- Coplotting designer and name works, while the two combination would not plot
- The linear model predicted infinite values and thus coplot the values properly for the other two options
- However, dropping all NA values and thus reducing the total data size to 354 observations would case for the combination coplot name and category while name + designer combination would not work
- The authors hypothesized that infinite values were caused by a division of zeros of the linear model since there occured 0 values in size
- This however proved to be wrong after applying respective filters

- The following interaction could be analyzed
- - There is probably no significant interaction between size, price, name & designer as can be seen in coplot -> lines are nearly parallel
- Based on the coplot of category and name with the 354 observations, inparallelity could be observed and thus could conclude a interaction. However, this could also be due to the small sample size 
-  


(footnote): the authors would highly appreciate any solutions on this matter



### Step 8: Independence of Price
- Durch das tidying in (cross reference) duplicate removal -> Zuur paper Step 8 1. citation: meaning that information from any one observation should not provide information on another after the effects of other variables have been accounted for. This concept is best explained with examples.


## Random Forest Regression Model {#tbd2}
- We chose rf
- random forest erklären -> article (for in depth reference see article)
- why random forest (not lm)? -> article to explain why random forest is great to explain feature importance
  - see article 
  - TODO: is normal distribution relevant for random forest (step 3) -> see article or site something
  
- To reproduce our results...
  - We chose randomForest R package for our analysis -> as in ... (cite article)
  - data base is tidy ikea (step ...)
  - then transform this data set to apply rf (johannes)
    - remove old price because of high correlation factor (step 5 + 6) which would fuck up our overall result
    - fct_lump erklären
    - rf has problems with na values -> 3 different methods to solve problem -> calculated 3 feature importances -> mean(a, b, c) 


















